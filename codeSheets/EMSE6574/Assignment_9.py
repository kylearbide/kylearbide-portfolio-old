# -*- coding: utf-8 -*-
"""TitanicRegression

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1iL6fx6dA_Sk_-foyuZvCQCLLht_tttVT
"""

from numpy import log, dot, e
import matplotlib.pyplot as plt
import pandas as pd

trainDf = pd.read_csv("train.csv")
testDf = pd.read_csv("test.csv")

trainDf.describe()

sum(trainDf["Age"].isna())

testDf.describe()

trainDf.columns

trainDf["Sex_num"] = [1 if x == "male" else 0 for x in trainDf["Sex"]]

trainDf.dropna(inplace=True)

from numpy.random import rand, randint

X = trainDf[["Pclass",'Age','SibSp', 'Parch',"Sex_num", "Fare"]]
Y = trainDf["Survived"]

weights = rand(X.shape[1])

def sigmoid(z): 
  return (1 / (1 + e**(-z)))

epsilon = 0.00000000000001

def predict(X):
  z=sigmoid(dot(X,weights))
  return([1 if i > 0.5 else 0 for i in z])

def cost_function(X,y,weights):
  y_hat = sigmoid(dot(X,weights))
  pred_1 = y*log(y_hat+epsilon)
  pred_0 = (1-y)*log(1-y_hat+epsilon)
  mean = - sum(pred_1 + pred_0)/len(X)
  return(mean)

cost_function(X,Y,weights)

def random_walk(X,y):
  best_weights = []
  best_cost = 1000000000
  cost = []

  for _ in range(25):
    weights = rand(X.shape[1])
    c = cost_function(X,y,weights) #<<<---- $$$$ cost
    if c < best_cost:
      best_cost=c
      best_weights=weights
      cost.append(best_cost)

  return(cost,best_weights)

l1, w1 = random_walk(X,Y)

plt.plot(l1)

def fit(X,y,epochs=25,lr=0.01):
  loss = []
  weights = rand(X.shape[1])
  n = len(X)
  for _ in range(epochs):
    y_hat = sigmoid(dot(X,weights))
    delta = lr* dot(X.T, y_hat-y)/n
    weights -= delta
    loss.append(cost_function(X,y,weights))

  return(loss,weights)

l2, w2 = fit(X,Y,epochs = 1000, lr=0.0001)

plt.plot(l2)

min(l2)

from sklearn.linear_model import LogisticRegression
from sklearn.linear_model import _logistic_loss

reg = LogisticRegression().fit(X,Y)

reg.score(X,Y)

(sum(abs(reg.predict(X)-Y)))**2